\section*{Abstract}

In this thesis, machine learning agents learn to play the online browser game \href{https://Slither.io}{Slither.io}. In \textit{Slither} you play as a snake where the goal is to grow, by killing other snakes and eating food pellets. There are over 100 snakes in a single arena, and every player competes against each other under the same circumstances. The game has simple rules and controls, and yet complicated situations constantly emerge. The agents are trained with multiple machine learning methods such as imitation learning and deep Q-learning. Actor-critic policy gradient methods like PPO and SAC are given special attention, as they have the greatest potential in training agents that achieve superhuman performance. If time allows, the more complicated model-based methods are explored. The agents can observe their environment in different ways. For example by passing visual images through a CNN. This training and observing is established with an in-house replica of Slither in the game-engine Unity. Unity uses an API for communication with Python's machine learning library PyTorch to implement the machine learning algorithms. The main goal of this thesis is to create a superhuman player in Slither which can be deployed onto the original browser game.  Additionally, the aim is to compare the performance of different algorithms and techniques, to better understand how to effectively and efficiently train agents on competitive video games.


